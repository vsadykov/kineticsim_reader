{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa15e33d",
   "metadata": {},
   "source": [
    "## Description of Notebook\n",
    "\n",
    "The notebook is used to test ML approach on the VDF statistical momenta, anisotropies, and particle fraction numbers. Here we also vary the labels based on the threshold (five categories of labels were defined during the data processing phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6223e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, ShuffleSplit\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, make_scorer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ec650e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outputclass_analysis(test_labels, predicted_labels, output_score=''):\n",
    "    tn, fp, fn, tp = confusion_matrix(test_labels, predicted_labels).ravel()\n",
    "    print(\"------------ SUMMARY OF CLASSIFICATION RESULTS ----------------\")\n",
    "    print(\"TP = \"+str(tp))\n",
    "    print(\"TN = \"+str(tn))\n",
    "    print(\"FP = \"+str(fp))\n",
    "    print(\"FN = \"+str(fn))\n",
    "    precision = tp/(tp+fp) if ((tp+fp) != 0) else -999.9\n",
    "    recall = tp/(tp+fn) if ((tp+fn) != 0) else -999.9\n",
    "    acc = (tp+tn)/(tp+fn+fp+tn)\n",
    "    tss = tp/(tp+fn) - fp/(fp+tn) if (((tp+fn) != 0) and ((fp+tn) != 0)) else -999.9\n",
    "    hss = 2*(tp*tn - fp*fn)/((tp+fn)*(fn+tn) + (tp+fp)*(fp+tn))\n",
    "    print(\"Precision = \"+str(precision))\n",
    "    print(\"Recall = \"+str(recall))\n",
    "    print(\"Accuracy = \"+str(acc))\n",
    "    print(\"TSS = \"+str(tss))\n",
    "    print(\"HSS = \"+str(hss))\n",
    "    if (output_score == 'TSS'): return tss\n",
    "    if (output_score == 'HSS'): return hss\n",
    "    if (output_score == 'precision'): return precision\n",
    "    if (output_score == 'accuracy'): return acc\n",
    "    return\n",
    "\n",
    "def outputclass_analysis_scorereturn(test_labels, predicted_labels):\n",
    "    matrix_elements = confusion_matrix(test_labels, predicted_labels, labels=[0, 1]).ravel()\n",
    "    tn, fp, fn, tp = matrix_elements\n",
    "    precision = tp/(tp+fp) if ((tp+fp) != 0) else -999.9\n",
    "    recall = tp/(tp+fn) if ((tp+fn) != 0) else -999.9\n",
    "    acc = (tp+tn)/(tp+fn+fp+tn)\n",
    "    tss = tp/(tp+fn) - fp/(fp+tn) if (((tp+fn) != 0) and ((fp+tn) != 0)) else -999.9\n",
    "    return tp, tn, fp, fn, acc, tss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333b4558",
   "metadata": {},
   "source": [
    "## Test 1. Preparation and testing of the data set.\n",
    "\n",
    "Various thresholds are tried here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da48ef5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- THRES = 001----------------------------------\n",
      "The total number of data points is: 1596\n",
      "Among them unstable (positive) samples: 1363\n",
      "------------------------- THRES = 005----------------------------------\n",
      "The total number of data points is: 1596\n",
      "Among them unstable (positive) samples: 681\n",
      "------------------------- THRES = 01----------------------------------\n",
      "The total number of data points is: 1596\n",
      "Among them unstable (positive) samples: 418\n",
      "------------------------- THRES = 05----------------------------------\n",
      "The total number of data points is: 1596\n",
      "Among them unstable (positive) samples: 110\n",
      "------------------------- THRES = 10----------------------------------\n",
      "The total number of data points is: 1596\n",
      "Among them unstable (positive) samples: 62\n"
     ]
    }
   ],
   "source": [
    "def label_union(indstr):\n",
    "    labels_an = np.load('./mldata_vdfmoments/allsimulations.labels_allmoments_an_'+indstr+'_all.npy')\n",
    "    labels_me = np.load('./mldata_vdfmoments/allsimulations.labels_allmoments_me_'+indstr+'_all.npy')\n",
    "    labels_allmoments = np.copy(labels_me)\n",
    "    labels_allmoments[np.where(labels_an == 1)] = 1\n",
    "    print('------------------------- THRES = ' + indstr + '----------------------------------')\n",
    "    print('The total number of data points is: ' + str(len(labels_allmoments)))\n",
    "    print('Among them unstable (positive) samples: ' + str(len(np.where(labels_allmoments == 1)[0])))\n",
    "    return labels_allmoments\n",
    "\n",
    "featurevector_allmoments = np.load('./mldata_vdfmoments/allsimulations.featurevector_allmoments_all.npy')\n",
    "times_allmoments = np.load('./mldata_vdfmoments/allsimulations.timep_array_all.npy')\n",
    "labels_allmoments_001 = label_union('001')\n",
    "labels_allmoments_005 = label_union('005')\n",
    "labels_allmoments_01 = label_union('01')\n",
    "labels_allmoments_05 = label_union('05')\n",
    "labels_allmoments_10 = label_union('10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "976894d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(featurevector_allmoments)\n",
    "featurevector_allmoments = scaler.transform(featurevector_allmoments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d098f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split = ShuffleSplit(n_splits=10, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2167463b",
   "metadata": {},
   "source": [
    "## Test 2. Random Forest on the data sets of various thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb51143",
   "metadata": {},
   "source": [
    "Given that Random Forest has demonstrated a good performance previously, we down-select it for the thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4e352b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "Testing for threshold THRES = 0.0001:\n",
      "Fitting 10 folds for each of 40 candidates, totalling 400 fits\n",
      "Best parameters found:  {'class_weight': 'balanced', 'max_depth': 10, 'n_estimators': 100}\n",
      "TP = 435.3+/-6.664082832618455\n",
      "TN = 71.3+/-5.367494760127857\n",
      "FP = 8.0+/-3.0\n",
      "FN = 12.4+/-2.33238075793812\n",
      "Acc = 0.9612903225806452+/-0.003907260015554844\n",
      "TSS = 0.8733232940514501+/-0.028799332646232665\n",
      "-------------------------------------\n",
      "Testing for threshold THRES = 0.0005:\n",
      "Fitting 10 folds for each of 40 candidates, totalling 400 fits\n",
      "Best parameters found:  {'class_weight': None, 'max_depth': None, 'n_estimators': 50}\n",
      "TP = 206.6+/-5.351635264103861\n",
      "TN = 293.7+/-5.478138369920935\n",
      "FP = 11.0+/-3.9496835316262997\n",
      "FN = 15.7+/-5.254521862167861\n",
      "Acc = 0.9493358633776092+/-0.00906258363283457\n",
      "TSS = 0.8938909543926948+/-0.019903829633524488\n",
      "-------------------------------------\n",
      "Testing for threshold THRES = 0.001:\n",
      "Fitting 10 folds for each of 40 candidates, totalling 400 fits\n",
      "Best parameters found:  {'class_weight': 'balanced', 'max_depth': 25, 'n_estimators': 200}\n",
      "TP = 121.8+/-5.979966555090422\n",
      "TN = 385.8+/-4.770744176750625\n",
      "FP = 6.9+/-3.0805843601498726\n",
      "FN = 12.5+/-3.9560080889704965\n",
      "Acc = 0.9631878557874762+/-0.008786213967962206\n",
      "TSS = 0.8892606644392668+/-0.02975419888334894\n",
      "-------------------------------------\n",
      "Testing for threshold THRES = 0.005:\n",
      "Fitting 10 folds for each of 40 candidates, totalling 400 fits\n",
      "Best parameters found:  {'class_weight': 'balanced', 'max_depth': 10, 'n_estimators': 100}\n",
      "TP = 28.0+/-4.147288270665544\n",
      "TN = 487.7+/-3.494281041931229\n",
      "FP = 3.7+/-2.3259406699226015\n",
      "FN = 7.6+/-3.0724582991474434\n",
      "Acc = 0.9785578747628083+/-0.006948703386565679\n",
      "TSS = 0.7795820109574884+/-0.07404323249402192\n",
      "-------------------------------------\n",
      "Testing for threshold THRES = 0.01:\n",
      "Fitting 10 folds for each of 40 candidates, totalling 400 fits\n",
      "Best parameters found:  {'class_weight': None, 'max_depth': 10, 'n_estimators': 50}\n",
      "TP = 14.8+/-1.98997487421324\n",
      "TN = 505.9+/-2.3000000000000003\n",
      "FP = 0.7+/-1.004987562112089\n",
      "FN = 5.6+/-2.1540659228538015\n",
      "Acc = 0.9880455407969639+/-0.003504019983419226\n",
      "TSS = 0.72724900784369+/-0.09288782721513834\n"
     ]
    }
   ],
   "source": [
    "def evaluate_RFclassifier(featurevector_allmoments, labels_allmoments, data_split):\n",
    "\n",
    "    # parameter grid\n",
    "    param_grid = {'n_estimators': [10,50,100,200], \\\n",
    "                  'max_depth': [None, 2, 5, 10, 25], \\\n",
    "                  'class_weight': [None, 'balanced']}\n",
    "\n",
    "    # classifier and gridsearch\n",
    "    clf = RandomForestClassifier()\n",
    "    grid_search = GridSearchCV(clf, param_grid, cv=data_split, verbose=1, scoring='accuracy')\n",
    "    grid_search.fit(featurevector_allmoments, labels_allmoments)\n",
    "    print(\"Best parameters found: \", grid_search.best_params_)\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # fitting 10 times and accumulating the scores for the best model\n",
    "    tp = np.zeros([10], dtype=int)\n",
    "    tn = np.zeros([10], dtype=int)\n",
    "    fp = np.zeros([10], dtype=int)\n",
    "    fn = np.zeros([10], dtype=int)\n",
    "    acc = np.zeros([10], dtype=float)\n",
    "    tss = np.zeros([10], dtype=float)\n",
    "\n",
    "    for i, split_indexes in enumerate(data_split.split(featurevector_allmoments)):\n",
    "        train_index, test_index = split_indexes\n",
    "        X_train, X_test = featurevector_allmoments[train_index], featurevector_allmoments[test_index]\n",
    "        f_train, f_test = labels_allmoments[train_index], labels_allmoments[test_index]\n",
    "        clf = RandomForestClassifier(**best_params)\n",
    "        clf.fit(X_train, f_train)\n",
    "        f_predicted = clf.predict(X_test)\n",
    "        tp[i], tn[i], fp[i], fn[i], acc[i], tss[i] = outputclass_analysis_scorereturn(f_test, f_predicted)\n",
    "\n",
    "    print(\"TP = \" + str(np.mean(tp)) + \"+/-\" + str(np.std(tp)))\n",
    "    print(\"TN = \" + str(np.mean(tn)) + \"+/-\" + str(np.std(tn)))\n",
    "    print(\"FP = \" + str(np.mean(fp)) + \"+/-\" + str(np.std(fp)))\n",
    "    print(\"FN = \" + str(np.mean(fn)) + \"+/-\" + str(np.std(fn)))\n",
    "    print(\"Acc = \" + str(np.mean(acc)) + \"+/-\" + str(np.std(acc)))\n",
    "    print(\"TSS = \" + str(np.mean(tss)) + \"+/-\" + str(np.std(tss)))\n",
    "    \n",
    "\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Testing for threshold THRES = 0.0001:\")\n",
    "evaluate_RFclassifier(featurevector_allmoments, labels_allmoments_001, data_split)\n",
    "\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Testing for threshold THRES = 0.0005:\")\n",
    "evaluate_RFclassifier(featurevector_allmoments, labels_allmoments_005, data_split)\n",
    "\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Testing for threshold THRES = 0.001:\")\n",
    "evaluate_RFclassifier(featurevector_allmoments, labels_allmoments_01, data_split)\n",
    "\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Testing for threshold THRES = 0.005:\")\n",
    "evaluate_RFclassifier(featurevector_allmoments, labels_allmoments_05, data_split)\n",
    "\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Testing for threshold THRES = 0.01:\")\n",
    "evaluate_RFclassifier(featurevector_allmoments, labels_allmoments_10, data_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586e63b8",
   "metadata": {},
   "source": [
    "Same as above but with the restricted class weight set to balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b387d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "Testing for threshold THRES = 0.0001:\n",
      "Fitting 10 folds for each of 40 candidates, totalling 400 fits\n",
      "Best parameters found:  {'class_weight': 'balanced', 'max_depth': 5, 'n_estimators': 10}\n",
      "TP = 417.4+/-8.777243302996675\n",
      "TN = 75.1+/-6.847627326307997\n",
      "FP = 4.2+/-1.4696938456699067\n",
      "FN = 30.3+/-6.649060083951716\n",
      "Acc = 0.9345351043643264+/-0.012068370866153968\n",
      "TSS = 0.8797083264868661+/-0.01935982146633678\n",
      "-------------------------------------\n",
      "Testing for threshold THRES = 0.0005:\n",
      "Fitting 10 folds for each of 40 candidates, totalling 400 fits\n",
      "Best parameters found:  {'class_weight': None, 'max_depth': None, 'n_estimators': 50}\n",
      "TP = 206.8+/-6.321392251711643\n",
      "TN = 293.9+/-6.268173577685927\n",
      "FP = 10.8+/-4.621688003316537\n",
      "FN = 15.5+/-4.631414470763764\n",
      "Acc = 0.9500948766603416+/-0.009677419354838703\n",
      "TSS = 0.8952542196251961+/-0.020106730224330627\n",
      "-------------------------------------\n",
      "Testing for threshold THRES = 0.001:\n",
      "Fitting 10 folds for each of 40 candidates, totalling 400 fits\n",
      "Best parameters found:  {'class_weight': None, 'max_depth': None, 'n_estimators': 100}\n",
      "TP = 122.1+/-6.139218191268331\n",
      "TN = 385.5+/-5.200961449578338\n",
      "FP = 7.2+/-2.6758176320519302\n",
      "FN = 12.2+/-3.8157568056677826\n",
      "Acc = 0.9631878557874763+/-0.008192422445891055\n",
      "TSS = 0.8906260503889323+/-0.028848706678848427\n",
      "-------------------------------------\n",
      "Testing for threshold THRES = 0.005:\n",
      "Fitting 10 folds for each of 40 candidates, totalling 400 fits\n",
      "Best parameters found:  {'class_weight': 'balanced', 'max_depth': 5, 'n_estimators': 50}\n",
      "TP = 30.1+/-4.570557952810575\n",
      "TN = 474.9+/-5.166236541235795\n",
      "FP = 16.5+/-3.4713109915419564\n",
      "FN = 5.5+/-2.4596747752497685\n",
      "Acc = 0.9582542694497154+/-0.0075901328273244775\n",
      "TSS = 0.8105680517363165+/-0.06625541069732382\n",
      "-------------------------------------\n",
      "Testing for threshold THRES = 0.01:\n",
      "Fitting 10 folds for each of 40 candidates, totalling 400 fits\n",
      "Best parameters found:  {'class_weight': 'balanced', 'max_depth': 5, 'n_estimators': 100}\n",
      "TP = 15.6+/-1.8547236990991407\n",
      "TN = 495.6+/-5.817215828899594\n",
      "FP = 11.0+/-5.549774770204643\n",
      "FN = 4.8+/-2.521904042583698\n",
      "Acc = 0.9700189753320683+/-0.01079427905375931\n",
      "TSS = 0.7488554436615986+/-0.10531257895365426\n"
     ]
    }
   ],
   "source": [
    "def tss_score(test_labels, predicted_labels):\n",
    "    matrix_elements = confusion_matrix(test_labels, predicted_labels, labels=[0, 1]).ravel()\n",
    "    tn, fp, fn, tp = matrix_elements\n",
    "    tss = tp/(tp+fn) - fp/(fp+tn) if (((tp+fn) != 0) and ((fp+tn) != 0)) else -999.9\n",
    "    return tss\n",
    "\n",
    "\n",
    "def evaluate_RFclassifier_score(featurevector_allmoments, labels_allmoments, data_split, tss_scorer):\n",
    "\n",
    "    # parameter grid\n",
    "    param_grid = {'n_estimators': [10,50,100,200], \\\n",
    "                  'max_depth': [None, 2, 5, 10, 25], \\\n",
    "                  'class_weight': [None, 'balanced']}\n",
    "\n",
    "    # classifier and gridsearch\n",
    "    clf = RandomForestClassifier()\n",
    "    grid_search = GridSearchCV(clf, param_grid, cv=data_split, verbose=1, scoring=tss_scorer)\n",
    "    grid_search.fit(featurevector_allmoments, labels_allmoments)\n",
    "    print(\"Best parameters found: \", grid_search.best_params_)\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # fitting 10 times and accumulating the scores for the best model\n",
    "    tp = np.zeros([10], dtype=int)\n",
    "    tn = np.zeros([10], dtype=int)\n",
    "    fp = np.zeros([10], dtype=int)\n",
    "    fn = np.zeros([10], dtype=int)\n",
    "    acc = np.zeros([10], dtype=float)\n",
    "    tss = np.zeros([10], dtype=float)\n",
    "\n",
    "    for i, split_indexes in enumerate(data_split.split(featurevector_allmoments)):\n",
    "        train_index, test_index = split_indexes\n",
    "        X_train, X_test = featurevector_allmoments[train_index], featurevector_allmoments[test_index]\n",
    "        f_train, f_test = labels_allmoments[train_index], labels_allmoments[test_index]\n",
    "        clf = RandomForestClassifier(**best_params)\n",
    "        clf.fit(X_train, f_train)\n",
    "        f_predicted = clf.predict(X_test)\n",
    "        tp[i], tn[i], fp[i], fn[i], acc[i], tss[i] = outputclass_analysis_scorereturn(f_test, f_predicted)\n",
    "\n",
    "    print(\"TP = \" + str(np.mean(tp)) + \"+/-\" + str(np.std(tp)))\n",
    "    print(\"TN = \" + str(np.mean(tn)) + \"+/-\" + str(np.std(tn)))\n",
    "    print(\"FP = \" + str(np.mean(fp)) + \"+/-\" + str(np.std(fp)))\n",
    "    print(\"FN = \" + str(np.mean(fn)) + \"+/-\" + str(np.std(fn)))\n",
    "    print(\"Acc = \" + str(np.mean(acc)) + \"+/-\" + str(np.std(acc)))\n",
    "    print(\"TSS = \" + str(np.mean(tss)) + \"+/-\" + str(np.std(tss)))\n",
    "    \n",
    "\n",
    "tss_scorer = make_scorer(tss_score, greater_is_better=True)\n",
    "    \n",
    "print(\"-------------------------------------\")\n",
    "print(\"Testing for threshold THRES = 0.0001:\")\n",
    "evaluate_RFclassifier_score(featurevector_allmoments, labels_allmoments_001, data_split, tss_scorer)\n",
    "\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Testing for threshold THRES = 0.0005:\")\n",
    "evaluate_RFclassifier_score(featurevector_allmoments, labels_allmoments_005, data_split, tss_scorer)\n",
    "\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Testing for threshold THRES = 0.001:\")\n",
    "evaluate_RFclassifier_score(featurevector_allmoments, labels_allmoments_01, data_split, tss_scorer)\n",
    "\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Testing for threshold THRES = 0.005:\")\n",
    "evaluate_RFclassifier_score(featurevector_allmoments, labels_allmoments_05, data_split, tss_scorer)\n",
    "\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Testing for threshold THRES = 0.01:\")\n",
    "evaluate_RFclassifier_score(featurevector_allmoments, labels_allmoments_10, data_split, tss_scorer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30116b5d",
   "metadata": {},
   "source": [
    "## Test 3. Same as above but for the data with power spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d70d38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- THRES = 001----------------------------------\n",
      "The total number of data points is: 1596\n",
      "Among them unstable (positive) samples: 1363\n",
      "------------------------- THRES = 005----------------------------------\n",
      "The total number of data points is: 1596\n",
      "Among them unstable (positive) samples: 681\n",
      "------------------------- THRES = 01----------------------------------\n",
      "The total number of data points is: 1596\n",
      "Among them unstable (positive) samples: 418\n",
      "------------------------- THRES = 05----------------------------------\n",
      "The total number of data points is: 1596\n",
      "Among them unstable (positive) samples: 110\n",
      "------------------------- THRES = 10----------------------------------\n",
      "The total number of data points is: 1596\n",
      "Among them unstable (positive) samples: 62\n"
     ]
    }
   ],
   "source": [
    "def label_union(indstr):\n",
    "    labels_an = np.load('./mldata_vdfmoments/allsimulations.labels_allmoments_an_'+indstr+'_allps.npy')\n",
    "    labels_me = np.load('./mldata_vdfmoments/allsimulations.labels_allmoments_me_'+indstr+'_allps.npy')\n",
    "    labels_allmoments = np.copy(labels_me)\n",
    "    labels_allmoments[np.where(labels_an == 1)] = 1\n",
    "    print('------------------------- THRES = ' + indstr + '----------------------------------')\n",
    "    print('The total number of data points is: ' + str(len(labels_allmoments)))\n",
    "    print('Among them unstable (positive) samples: ' + str(len(np.where(labels_allmoments == 1)[0])))\n",
    "    return labels_allmoments\n",
    "\n",
    "featurevector_allmoments = np.load('./mldata_vdfmoments/allsimulations.featurevector_allmoments_allps.npy')\n",
    "times_allmoments = np.load('./mldata_vdfmoments/allsimulations.timep_array_allps.npy')\n",
    "labels_allmoments_001 = label_union('001')\n",
    "labels_allmoments_005 = label_union('005')\n",
    "labels_allmoments_01 = label_union('01')\n",
    "labels_allmoments_05 = label_union('05')\n",
    "labels_allmoments_10 = label_union('10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdc71954",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(featurevector_allmoments)\n",
    "featurevector_allmoments = scaler.transform(featurevector_allmoments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37c9f4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split = ShuffleSplit(n_splits=10, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fe3badb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "Testing for threshold THRES = 0.0001:\n",
      "Fitting 10 folds for each of 40 candidates, totalling 400 fits\n",
      "Best parameters found:  {'class_weight': 'balanced', 'max_depth': 10, 'n_estimators': 200}\n",
      "TP = 435.5+/-7.0178344238090995\n",
      "TN = 69.7+/-5.273518749374083\n",
      "FP = 9.6+/-3.4698703145794947\n",
      "FN = 12.2+/-2.6758176320519302\n",
      "Acc = 0.9586337760910816+/-0.00592808324546996\n",
      "TSS = 0.8536900113303822+/-0.033144222483425786\n",
      "-------------------------------------\n",
      "Testing for threshold THRES = 0.0005:\n",
      "Fitting 10 folds for each of 40 candidates, totalling 400 fits\n",
      "Best parameters found:  {'class_weight': 'balanced', 'max_depth': 25, 'n_estimators': 50}\n",
      "TP = 207.6+/-5.023942674832188\n",
      "TN = 293.9+/-7.063285354564121\n",
      "FP = 10.8+/-3.370459909270543\n",
      "FN = 14.7+/-5.040833264451424\n",
      "Acc = 0.9516129032258066+/-0.010436432637571148\n",
      "TSS = 0.8989368471317333+/-0.022424705612163826\n",
      "-------------------------------------\n",
      "Testing for threshold THRES = 0.001:\n",
      "Fitting 10 folds for each of 40 candidates, totalling 400 fits\n",
      "Best parameters found:  {'class_weight': None, 'max_depth': None, 'n_estimators': 100}\n",
      "TP = 121.6+/-6.1838499334961226\n",
      "TN = 385.5+/-5.9707620954112715\n",
      "FP = 7.2+/-3.3105890714493698\n",
      "FN = 12.7+/-3.976179070414209\n",
      "Acc = 0.9622390891840608+/-0.00927464850842499\n",
      "TSS = 0.8869044007120526+/-0.029769085056586746\n",
      "-------------------------------------\n",
      "Testing for threshold THRES = 0.005:\n",
      "Fitting 10 folds for each of 40 candidates, totalling 400 fits\n",
      "Best parameters found:  {'class_weight': None, 'max_depth': 25, 'n_estimators': 200}\n",
      "TP = 28.2+/-4.019950248448357\n",
      "TN = 488.3+/-3.6891733491393435\n",
      "FP = 3.1+/-2.5475478405714\n",
      "FN = 7.4+/-3.1368774282716245\n",
      "Acc = 0.9800759013282733+/-0.0072628687700207455\n",
      "TSS = 0.7870555203652675+/-0.07451416826203272\n",
      "-------------------------------------\n",
      "Testing for threshold THRES = 0.01:\n",
      "Fitting 10 folds for each of 40 candidates, totalling 400 fits\n",
      "Best parameters found:  {'class_weight': None, 'max_depth': 25, 'n_estimators': 200}\n",
      "TP = 14.1+/-2.2561028345356955\n",
      "TN = 505.9+/-2.4677925358506134\n",
      "FP = 0.7+/-0.45825756949558405\n",
      "FN = 6.3+/-2.5317977802344327\n",
      "Acc = 0.9867172675521821+/-0.004948161218370132\n",
      "TSS = 0.6933200473732961+/-0.10919675288882118\n"
     ]
    }
   ],
   "source": [
    "def evaluate_RFclassifier(featurevector_allmoments, labels_allmoments, data_split):\n",
    "\n",
    "    # parameter grid\n",
    "    param_grid = {'n_estimators': [10,50,100,200], \\\n",
    "                  'max_depth': [None, 2, 5, 10, 25], \\\n",
    "                  'class_weight': [None, 'balanced']}\n",
    "\n",
    "    # classifier and gridsearch\n",
    "    clf = RandomForestClassifier()\n",
    "    grid_search = GridSearchCV(clf, param_grid, cv=data_split, verbose=1, scoring='accuracy')\n",
    "    grid_search.fit(featurevector_allmoments, labels_allmoments)\n",
    "    print(\"Best parameters found: \", grid_search.best_params_)\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # fitting 10 times and accumulating the scores for the best model\n",
    "    tp = np.zeros([10], dtype=int)\n",
    "    tn = np.zeros([10], dtype=int)\n",
    "    fp = np.zeros([10], dtype=int)\n",
    "    fn = np.zeros([10], dtype=int)\n",
    "    acc = np.zeros([10], dtype=float)\n",
    "    tss = np.zeros([10], dtype=float)\n",
    "\n",
    "    for i, split_indexes in enumerate(data_split.split(featurevector_allmoments)):\n",
    "        train_index, test_index = split_indexes\n",
    "        X_train, X_test = featurevector_allmoments[train_index], featurevector_allmoments[test_index]\n",
    "        f_train, f_test = labels_allmoments[train_index], labels_allmoments[test_index]\n",
    "        clf = RandomForestClassifier(**best_params)\n",
    "        clf.fit(X_train, f_train)\n",
    "        f_predicted = clf.predict(X_test)\n",
    "        tp[i], tn[i], fp[i], fn[i], acc[i], tss[i] = outputclass_analysis_scorereturn(f_test, f_predicted)\n",
    "\n",
    "    print(\"TP = \" + str(np.mean(tp)) + \"+/-\" + str(np.std(tp)))\n",
    "    print(\"TN = \" + str(np.mean(tn)) + \"+/-\" + str(np.std(tn)))\n",
    "    print(\"FP = \" + str(np.mean(fp)) + \"+/-\" + str(np.std(fp)))\n",
    "    print(\"FN = \" + str(np.mean(fn)) + \"+/-\" + str(np.std(fn)))\n",
    "    print(\"Acc = \" + str(np.mean(acc)) + \"+/-\" + str(np.std(acc)))\n",
    "    print(\"TSS = \" + str(np.mean(tss)) + \"+/-\" + str(np.std(tss)))\n",
    "    \n",
    "\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Testing for threshold THRES = 0.0001:\")\n",
    "evaluate_RFclassifier(featurevector_allmoments, labels_allmoments_001, data_split)\n",
    "\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Testing for threshold THRES = 0.0005:\")\n",
    "evaluate_RFclassifier(featurevector_allmoments, labels_allmoments_005, data_split)\n",
    "\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Testing for threshold THRES = 0.001:\")\n",
    "evaluate_RFclassifier(featurevector_allmoments, labels_allmoments_01, data_split)\n",
    "\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Testing for threshold THRES = 0.005:\")\n",
    "evaluate_RFclassifier(featurevector_allmoments, labels_allmoments_05, data_split)\n",
    "\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Testing for threshold THRES = 0.01:\")\n",
    "evaluate_RFclassifier(featurevector_allmoments, labels_allmoments_10, data_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18ffbcde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "Testing for threshold THRES = 0.0001:\n",
      "Fitting 10 folds for each of 40 candidates, totalling 400 fits\n",
      "Best parameters found:  {'class_weight': 'balanced', 'max_depth': 5, 'n_estimators': 100}\n",
      "TP = 426.3+/-10.159232254457025\n",
      "TN = 74.2+/-5.89576118919347\n",
      "FP = 5.1+/-2.947880594596735\n",
      "FN = 21.4+/-6.711184694225007\n",
      "Acc = 0.9497153700189752+/-0.012904620976029823\n",
      "TSS = 0.8894599427968715+/-0.03339451441033196\n",
      "-------------------------------------\n",
      "Testing for threshold THRES = 0.0005:\n",
      "Fitting 10 folds for each of 40 candidates, totalling 400 fits\n",
      "Best parameters found:  {'class_weight': None, 'max_depth': 25, 'n_estimators': 200}\n",
      "TP = 207.3+/-5.1000000000000005\n",
      "TN = 294.0+/-7.0\n",
      "FP = 10.7+/-3.950949253027682\n",
      "FN = 15.0+/-4.381780460041329\n",
      "Acc = 0.9512333965844404+/-0.010114047796004891\n",
      "TSS = 0.8978686577010769+/-0.020736718025196818\n",
      "-------------------------------------\n",
      "Testing for threshold THRES = 0.001:\n",
      "Fitting 10 folds for each of 40 candidates, totalling 400 fits\n",
      "Best parameters found:  {'class_weight': None, 'max_depth': 25, 'n_estimators': 200}\n",
      "TP = 121.0+/-5.60357029044876\n",
      "TN = 385.6+/-5.370288632839021\n",
      "FP = 7.1+/-3.3301651610693423\n",
      "FN = 13.3+/-3.716180835212409\n",
      "Acc = 0.9612903225806452+/-0.008409305429282865\n",
      "TSS = 0.8828451331448667+/-0.026830495716417456\n",
      "-------------------------------------\n",
      "Testing for threshold THRES = 0.005:\n",
      "Fitting 10 folds for each of 40 candidates, totalling 400 fits\n",
      "Best parameters found:  {'class_weight': 'balanced', 'max_depth': 5, 'n_estimators': 200}\n",
      "TP = 29.2+/-4.422668877499197\n",
      "TN = 476.5+/-5.123475382979799\n",
      "FP = 14.9+/-3.6180105030251086\n",
      "FN = 6.4+/-3.5832945734337835\n",
      "Acc = 0.9595825426944972+/-0.01039494946854069\n",
      "TSS = 0.7913227312027219+/-0.08936882727130394\n",
      "-------------------------------------\n",
      "Testing for threshold THRES = 0.01:\n",
      "Fitting 10 folds for each of 40 candidates, totalling 400 fits\n",
      "Best parameters found:  {'class_weight': 'balanced', 'max_depth': 5, 'n_estimators': 200}\n",
      "TP = 15.2+/-2.181742422927143\n",
      "TN = 497.7+/-5.866003750424986\n",
      "FP = 8.9+/-5.5578772926361015\n",
      "FN = 5.2+/-2.521904042583698\n",
      "Acc = 0.9732447817836812+/-0.01143096431258373\n",
      "TSS = 0.7316732042065357+/-0.11037188337710938\n"
     ]
    }
   ],
   "source": [
    "def tss_score(test_labels, predicted_labels):\n",
    "    matrix_elements = confusion_matrix(test_labels, predicted_labels, labels=[0, 1]).ravel()\n",
    "    tn, fp, fn, tp = matrix_elements\n",
    "    tss = tp/(tp+fn) - fp/(fp+tn) if (((tp+fn) != 0) and ((fp+tn) != 0)) else -999.9\n",
    "    return tss\n",
    "\n",
    "\n",
    "def evaluate_RFclassifier_score(featurevector_allmoments, labels_allmoments, data_split, tss_scorer):\n",
    "\n",
    "    # parameter grid\n",
    "    param_grid = {'n_estimators': [10,50,100,200], \\\n",
    "                  'max_depth': [None, 2, 5, 10, 25], \\\n",
    "                  'class_weight': [None, 'balanced']}\n",
    "\n",
    "    # classifier and gridsearch\n",
    "    clf = RandomForestClassifier()\n",
    "    grid_search = GridSearchCV(clf, param_grid, cv=data_split, verbose=1, scoring=tss_scorer)\n",
    "    grid_search.fit(featurevector_allmoments, labels_allmoments)\n",
    "    print(\"Best parameters found: \", grid_search.best_params_)\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # fitting 10 times and accumulating the scores for the best model\n",
    "    tp = np.zeros([10], dtype=int)\n",
    "    tn = np.zeros([10], dtype=int)\n",
    "    fp = np.zeros([10], dtype=int)\n",
    "    fn = np.zeros([10], dtype=int)\n",
    "    acc = np.zeros([10], dtype=float)\n",
    "    tss = np.zeros([10], dtype=float)\n",
    "\n",
    "    for i, split_indexes in enumerate(data_split.split(featurevector_allmoments)):\n",
    "        train_index, test_index = split_indexes\n",
    "        X_train, X_test = featurevector_allmoments[train_index], featurevector_allmoments[test_index]\n",
    "        f_train, f_test = labels_allmoments[train_index], labels_allmoments[test_index]\n",
    "        clf = RandomForestClassifier(**best_params)\n",
    "        clf.fit(X_train, f_train)\n",
    "        f_predicted = clf.predict(X_test)\n",
    "        tp[i], tn[i], fp[i], fn[i], acc[i], tss[i] = outputclass_analysis_scorereturn(f_test, f_predicted)\n",
    "\n",
    "    print(\"TP = \" + str(np.mean(tp)) + \"+/-\" + str(np.std(tp)))\n",
    "    print(\"TN = \" + str(np.mean(tn)) + \"+/-\" + str(np.std(tn)))\n",
    "    print(\"FP = \" + str(np.mean(fp)) + \"+/-\" + str(np.std(fp)))\n",
    "    print(\"FN = \" + str(np.mean(fn)) + \"+/-\" + str(np.std(fn)))\n",
    "    print(\"Acc = \" + str(np.mean(acc)) + \"+/-\" + str(np.std(acc)))\n",
    "    print(\"TSS = \" + str(np.mean(tss)) + \"+/-\" + str(np.std(tss)))\n",
    "    \n",
    "\n",
    "tss_scorer = make_scorer(tss_score, greater_is_better=True)\n",
    "    \n",
    "print(\"-------------------------------------\")\n",
    "print(\"Testing for threshold THRES = 0.0001:\")\n",
    "evaluate_RFclassifier_score(featurevector_allmoments, labels_allmoments_001, data_split, tss_scorer)\n",
    "\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Testing for threshold THRES = 0.0005:\")\n",
    "evaluate_RFclassifier_score(featurevector_allmoments, labels_allmoments_005, data_split, tss_scorer)\n",
    "\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Testing for threshold THRES = 0.001:\")\n",
    "evaluate_RFclassifier_score(featurevector_allmoments, labels_allmoments_01, data_split, tss_scorer)\n",
    "\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Testing for threshold THRES = 0.005:\")\n",
    "evaluate_RFclassifier_score(featurevector_allmoments, labels_allmoments_05, data_split, tss_scorer)\n",
    "\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Testing for threshold THRES = 0.01:\")\n",
    "evaluate_RFclassifier_score(featurevector_allmoments, labels_allmoments_10, data_split, tss_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53d544f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
