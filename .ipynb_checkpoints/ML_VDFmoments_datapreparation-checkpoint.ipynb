{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa15e33d",
   "metadata": {},
   "source": [
    "## Description of Notebook\n",
    "\n",
    "The notebook is used to look closer into VDFs and the fields files in order to identify the stable and unstable periods. This notebook is also used to prepare the data for the machine learning (yet without the partitioning of the data into the train and test data sets which will be done separately)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6223e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import kineticsim_reader as kr\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "from scipy.signal import savgol_filter\n",
    "from tqdm import tqdm\n",
    "from matplotlib.animation import FuncAnimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3eb824ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "simfiles = ['particles.d11_A0.5Hepp_beta0.5eps1e-4_256',\\\n",
    "    'particles.d11_A0.75Hepp_beta1_256',\\\n",
    "    'particles.d11_E11Ap3.3Aa2.0Vd0.42',\\\n",
    "    'particles.d11_E11Ap4.3Aa1.6',\\\n",
    "    'particles.d11_E11Ap4.3Aa1.6Vd0.32',\\\n",
    "    'particles.d11_E12Ap1.86Aa1.0Vd0.32_256_256x256',\\\n",
    "    'particles.d11_E12Ap1.86Aa1.0Vd0.32_512_256x256',\\\n",
    "    'particles.d11_He++A10_256_iden0eps0',\\\n",
    "    'particles.d11_He++v2_256_iden0eps1e-4t600',\\\n",
    "    'particles.d11_He++vd1.5_256_iden0eps1e-4',\\\n",
    "    'particles.d11_pv1.5_128_64_iden0eps1e-4_dx0.75_long',\\\n",
    "    'particles.d11_pv1Ap2Apb2betac0.214betab0.858_128_128x2_dx0.75_t3000',\\\n",
    "    'particles.d11_pv2a_128x3_iden0eps1e-4_dx0.75',\\\n",
    "    'particles.d11_pv2Ap1Ab1betac0.429betab0.858_128_128x2_dx0.75_t3000',\\\n",
    "    'particles.d11_pv2Ap1Ab2betac0.429betab0.858_128_128x2_dx0.75_t3000',\\\n",
    "    'particles.d11_pv2Ap2Apb2betac0.214betab0.858_128_128x2_dx0.75_t3000',\\\n",
    "    'particles.d11_pv2av2.3_128x3_iden0eps1e-4_dx0.75',\\\n",
    "    'particles.d11_pv2av2Ap1Aa1beta0.429_128_128x2_dx0.75_t3000',\\\n",
    "    'particles.d11_pv2av2_rdna0.03375_128x3_iden0eps1e-4_dx0.75_t6000',\\\n",
    "    'particles.d11_vap1.2Ap1Aa0.75_rdna_0.05',\\\n",
    "    'particles.d11_vap1.2Ap3.35Aa2.05rdna_0.007',\\\n",
    "    'particles.d11_vap1.5Ap1.5Aa1rdna_0.007']\n",
    "\n",
    "fldfiles = ['fields.d10_A0.5Hepp_beta0.5eps1e-4_256',\\\n",
    "    'fields.d10_A0.75Hepp_beta1_256',\\\n",
    "    'fields.d10_E11Ap3.3Aa2.0Vd0.42',\\\n",
    "    'fields.d10_E11Ap4.3Aa1.6',\\\n",
    "    'fields.d10_E11Ap4.3Aa1.6Vd0.32',\\\n",
    "    'fields.d10_E12Ap1.86Aa1.0Vd0.32_256_256x256',\\\n",
    "    'fields.d10_E12Ap1.86Aa1.0Vd0.32_512_256x256',\\\n",
    "    'fields.d10_He++A10_256_iden0eps0',\\\n",
    "    'fields.d10_He++v2_256_iden0eps1e-4t600',\\\n",
    "    'fields.d10_He++vd1.5_256_iden0eps1e-4',\\\n",
    "    'fields.d10_pv1.5_128_64_iden0eps1e-4_dx0.75_long',\\\n",
    "    'fields.d10_pv1Ap2Apb2betac0.214betab0.858_128_128x2_dx0.75_t3000',\\\n",
    "    'fields.d10_pv2a_128x3_iden0eps1e-4_dx0.75',\\\n",
    "    'fields.d10_pv2Ap1Ab1betac0.429betab0.858_128_128x2_dx0.75_t3000',\\\n",
    "    'fields.d10_pv2Ap1Ab2betac0.429betab0.858_128_128x2_dx0.75_t3000',\\\n",
    "    'fields.d10_pv2Ap2Apb2betac0.214betab0.858_128_128x2_dx0.75_t3000',\\\n",
    "    'fields.d10_pv2av2.3_128x3_iden0eps1e-4_dx0.75',\\\n",
    "    'fields.d10_pv2av2Ap1Aa1beta0.429_128_128x2_dx0.75_t3000',\\\n",
    "    'fields.d10_pv2av2_rdna0.03375_128x3_iden0eps1e-4_dx0.75_t6000',\\\n",
    "    'fields.d10_vap1.2Ap1Aa0.75_rdna_0.05',\\\n",
    "    'fields.d10_vap1.2Ap3.35Aa2.05rdna_0.007',\\\n",
    "    'fields.d10_vap1.5Ap1.5Aa1rdna_0.007']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e34eb3e",
   "metadata": {},
   "source": [
    "## MORE INSPECTION NEEDED !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16949b7c",
   "metadata": {},
   "source": [
    "## Determination of stable and unstable VDFs\n",
    "\n",
    "This overall remains an open question. Inspections of the VDFs and time parameters revealed the cases when the magnetic energy remains stable, but the anisotropies and temperatures change/exchange.\n",
    "\n",
    "Given the definition uncertainties above, we will implement several labeling approaches. First, the separate labelings will be developed for the magnetic energy and anisotropy following these thresholds:\n",
    "1. The simulation runs are classified: if the change of anisotropies or perpendicular magnetic energy is more than 0.1% per one gyroperiod, the VDFs are called unstable.\n",
    "2. The simulation runs are classified: if the change of anisotropies or perpendicular magnetic energy is more than 0.5% per one gyroperiod, the VDFs are called unstable.\n",
    "3. The simulation runs are classified: if the change of anisotropies or perpendicular magnetic energy is more than 1.0% per one gyroperiod, the VDFs are called unstable.\n",
    "4. The simulation runs are NOT classified. Instead, the regression problem will be solved for both the anisotropies and magnetic energies."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dddb6001",
   "metadata": {},
   "source": [
    "The figures seem to be reasonable, except for the following cases where the labeling has to be adjusted:\n",
    "- Simulation run 'particles.d11_A0.5Hepp_beta0.5eps1e-4_256': magnetic energy should become stable after the first 4 simulation data points. The oscillations in magnetic energy are numerical.\n",
    "- Simulation run 'particles.d11_A0.75Hepp_beta1_256': magnetic energy should become stable after the first 2 simulation data points. The oscillations in magnetic energy are numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bd3b4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML data for the simulation particles.d11_A0.5Hepp_beta0.5eps1e-4_256 generated\n",
      "Number of data points: 80\n",
      "ML data for the simulation particles.d11_A0.75Hepp_beta1_256 generated\n",
      "Number of data points: 48\n",
      "ML data for the simulation particles.d11_E11Ap3.3Aa2.0Vd0.42 generated\n",
      "Number of data points: 48\n",
      "ML data for the simulation particles.d11_E11Ap4.3Aa1.6 generated\n",
      "Number of data points: 48\n",
      "ML data for the simulation particles.d11_E11Ap4.3Aa1.6Vd0.32 generated\n",
      "Number of data points: 48\n",
      "ML data for the simulation particles.d11_E12Ap1.86Aa1.0Vd0.32_256_256x256 generated\n",
      "Number of data points: 50\n",
      "ML data for the simulation particles.d11_E12Ap1.86Aa1.0Vd0.32_512_256x256 generated\n",
      "Number of data points: 50\n",
      "ML data for the simulation particles.d11_He++A10_256_iden0eps0 generated\n",
      "Number of data points: 48\n",
      "ML data for the simulation particles.d11_He++v2_256_iden0eps1e-4t600 generated\n",
      "Number of data points: 92\n",
      "ML data for the simulation particles.d11_He++vd1.5_256_iden0eps1e-4 generated\n",
      "Number of data points: 80\n",
      "ML data for the simulation particles.d11_pv1.5_128_64_iden0eps1e-4_dx0.75_long generated\n",
      "Number of data points: 150\n",
      "ML data for the simulation particles.d11_pv2a_128x3_iden0eps1e-4_dx0.75 generated\n",
      "Number of data points: 75\n",
      "ML data for the simulation particles.d11_pv2av2_rdna0.03375_128x3_iden0eps1e-4_dx0.75_t6000 generated\n",
      "Number of data points: 37\n",
      "ML data for the simulation particles.d11_pv2av2.3_128x3_iden0eps1e-4_dx0.75 generated\n",
      "Number of data points: 63\n",
      "ML data for the simulation particles.d11_vap1.2Ap1Aa0.75_rdna_0.05 generated\n",
      "Number of data points: 24\n",
      "ML data for the simulation particles.d11_vap1.2Ap3.35Aa2.05rdna_0.007 generated\n",
      "Number of data points: 24\n",
      "ML data for the simulation particles.d11_vap1.5Ap1.5Aa1rdna_0.007 generated\n",
      "Number of data points: 32\n"
     ]
    }
   ],
   "source": [
    "def prepare_mldata_vdfmoments(simfile, fieldsfile):\n",
    "    \n",
    "    timep_array = np.load('./processing_results/' + simfile + '.timep_array.npy')\n",
    "    anisotropies_p = np.load('./processing_results/' + simfile + '.anisotropies_p.npy')\n",
    "    moments_p = np.load('./processing_results/' + simfile + '.moments_p.npy')\n",
    "    anisotropies_he = np.load('./processing_results/' + simfile + '.anisotropies_he.npy')\n",
    "    moments_he = np.load('./processing_results/' + simfile + '.moments_he.npy')\n",
    "    \n",
    "    if (simfile == 'particles.d11_pv1.5_128_64_iden0eps1e-4_dx0.75_long'):\n",
    "        vdfp_array_p1 = np.load('./processing_results/' + simfile + '_p1.vdfp_array.npy')\n",
    "        vdfhe_array_p1 = np.load('./processing_results/' + simfile + '_p1.vdfhe_array.npy')\n",
    "        vdfp_array_p2 = np.load('./processing_results/' + simfile + '_p2.vdfp_array.npy')\n",
    "        vdfhe_array_p2 = np.load('./processing_results/' + simfile + '_p2.vdfhe_array.npy')\n",
    "        vdfp_array = np.concatenate((vdfp_array_p1, vdfp_array_p2))\n",
    "        vdfhe_array = np.concatenate((vdfhe_array_p1, vdfhe_array_p2))\n",
    "    else:\n",
    "        vdfp_array = np.load('./processing_results/' + simfile + '.vdfp_array.npy')\n",
    "        vdfhe_array = np.load('./processing_results/' + simfile + '.vdfhe_array.npy')\n",
    "    \n",
    "    timep_array_fields = np.load('./processing_results/' + fieldsfile + '.timing.npy')[:,1]\n",
    "    me_perp = np.load('./processing_results/' + fieldsfile + '.me_perp.npy')\n",
    "    me_tot = np.load('./processing_results/' + fieldsfile + '.me_tot.npy')\n",
    "    # applying smoothing to remove a periodic signal\n",
    "    dtime = timep_array_fields[1] - timep_array_fields[0]\n",
    "    npoints = int(len(me_tot)/10)\n",
    "    if (npoints % 2 == 0): npoints = npoints + 1\n",
    "    me_tot = savgol_filter(me_tot - me_tot[0], npoints, 3)\n",
    "    me_perp = savgol_filter(me_perp, npoints, 3)\n",
    "    \n",
    "    # resampling to the timing of the VDFs\n",
    "    me_tot = np.interp(timep_array,timep_array_fields,me_tot)\n",
    "    me_perp = np.interp(timep_array,timep_array_fields,me_perp)\n",
    "    \n",
    "    # time derivatives (relative)\n",
    "    dt_anisotropies_p = (anisotropies_p[1:]-anisotropies_p[:-1])/(timep_array[1:]-timep_array[:-1])\n",
    "    dt_anisotropies_p = 2*(dt_anisotropies_p)/(anisotropies_p[1:]+anisotropies_p[:-1])\n",
    "    dt_anisotropies_he = (anisotropies_he[1:]-anisotropies_he[:-1])/(timep_array[1:]-timep_array[:-1])\n",
    "    dt_anisotropies_he = 2*(dt_anisotropies_he)/(anisotropies_he[1:]+anisotropies_he[:-1])\n",
    "    dt_me_perp = (me_perp[1:]-me_perp[:-1])/(timep_array[1:]-timep_array[:-1])\n",
    "    dt_me_perp = 2*(dt_me_perp)/(me_perp[1:]+me_perp[:-1])\n",
    "    dt_me_tot = (me_tot[1:]-me_tot[:-1])/(timep_array[1:]-timep_array[:-1])\n",
    "    dt_me_tot = 2*(dt_me_tot)/(me_tot[1:]+me_tot[:-1])\n",
    "    \n",
    "    # declaring feature vectors and moments\n",
    "    featurevector_allmoments = []\n",
    "    labels_allmoments_01 = []\n",
    "    labels_allmoments_05 = []\n",
    "    labels_allmoments_10 = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range (0, len(timep_array)-1, 1):\n",
    "        subvector = []\n",
    "        subvector.append(moments_p[i,0,0])\n",
    "        subvector.append(moments_p[i,0,1])\n",
    "        subvector.append(moments_p[i,1,0])\n",
    "        subvector.append(moments_p[i,1,1])\n",
    "        subvector.append(moments_p[i,2,0])\n",
    "        subvector.append(moments_p[i,2,1])\n",
    "        subvector.append(moments_p[i,3,0])\n",
    "        subvector.append(moments_p[i,3,1])\n",
    "        subvector.append(moments_he[i,0,0])\n",
    "        subvector.append(moments_he[i,0,1])\n",
    "        subvector.append(moments_he[i,1,0])\n",
    "        subvector.append(moments_he[i,1,1])\n",
    "        subvector.append(moments_he[i,2,0])\n",
    "        subvector.append(moments_he[i,2,1])\n",
    "        subvector.append(moments_he[i,3,0])\n",
    "        subvector.append(moments_he[i,3,1])\n",
    "        subvector.append(anisotropies_p[i])\n",
    "        subvector.append(anisotropies_he[i])\n",
    "        \n",
    "        # HERE IS A PLACE FOR MORE DESCRIPTORS\n",
    "        \n",
    "        \n",
    "        subvector.append(np.log10(np.sum(vdfp_array[i,:,:])))\n",
    "        subvector.append(np.log10(np.sum(vdfhe_array[i,:,:])))\n",
    "        subvector.append(1)\n",
    "        \n",
    "        \n",
    "        # HERE IS A PLACE FOR MORE LOGIC ON THRESHOLDS\n",
    "        \n",
    "        # omitting initial time moments for some simulations\n",
    "        if ((simfile == 'particles.d11_A0.5Hepp_beta0.5eps1e-4_256') and (timep_array[i] < 200)):\n",
    "            labels_allmoments.append(0)\n",
    "            featurevector_allmoments.append(subvector)\n",
    "            continue\n",
    "        if ((simfile == 'particles.d11_A0.75Hepp_beta1_256') and (timep_array[i] < 200)):\n",
    "            labels_allmoments.append(0)\n",
    "            featurevector_allmoments.append(subvector)\n",
    "            continue\n",
    "        if ((simfile == 'particles.d11_vap1.2Ap1Aa0.75_rdna_0.05') and (timep_array[i] < 200)):\n",
    "            labels_allmoments.append(0)\n",
    "            featurevector_allmoments.append(subvector)\n",
    "            continue\n",
    "        if ((simfile == 'particles.d11_vap1.2Ap3.35Aa2.05rdna_0.007') and (timep_array[i] < 200)):\n",
    "            labels_allmoments.append(0)\n",
    "            featurevector_allmoments.append(subvector)\n",
    "            continue\n",
    "        if ((simfile == 'particles.d11_vap1.5Ap1.5Aa1rdna_0.007') and (timep_array[i] < 200)):\n",
    "            labels_allmoments.append(0)\n",
    "            featurevector_allmoments.append(subvector)\n",
    "            continue\n",
    "        # instability condition\n",
    "        if ((np.abs(dt_anisotropies_p[i]) > 0.001) or (np.abs(dt_anisotropies_he[i]) > 0.001) \\\n",
    "            or (np.abs(dt_me_perp[i]) > 0.001)):\n",
    "            labels_allmoments.append(1)\n",
    "            featurevector_allmoments.append(subvector)\n",
    "        else:\n",
    "            labels_allmoments.append(0)\n",
    "            featurevector_allmoments.append(subvector)\n",
    "            \n",
    "    featurevector_allmoments = np.array(featurevector_allmoments, dtype='float')\n",
    "    labels_allmoments = np.array(labels_allmoments, dtype='float')\n",
    "    return featurevector_allmoments, labels_allmoments, timep_array\n",
    "    \n",
    "    \n",
    "simfiles = ['particles.d11_A0.5Hepp_beta0.5eps1e-4_256',\\\n",
    "            'particles.d11_A0.75Hepp_beta1_256',\\\n",
    "            'particles.d11_E11Ap3.3Aa2.0Vd0.42',\\\n",
    "            'particles.d11_E11Ap4.3Aa1.6',\\\n",
    "            'particles.d11_E11Ap4.3Aa1.6Vd0.32',\\\n",
    "            'particles.d11_E12Ap1.86Aa1.0Vd0.32_256_256x256',\\\n",
    "            'particles.d11_E12Ap1.86Aa1.0Vd0.32_512_256x256',\\\n",
    "            'particles.d11_He++A10_256_iden0eps0',\\\n",
    "            'particles.d11_He++v2_256_iden0eps1e-4t600',\\\n",
    "            'particles.d11_He++vd1.5_256_iden0eps1e-4',\\\n",
    "            'particles.d11_pv1.5_128_64_iden0eps1e-4_dx0.75_long',\\\n",
    "            'particles.d11_pv2a_128x3_iden0eps1e-4_dx0.75',\\\n",
    "            'particles.d11_pv2av2_rdna0.03375_128x3_iden0eps1e-4_dx0.75_t6000',\\\n",
    "            'particles.d11_pv2av2.3_128x3_iden0eps1e-4_dx0.75',\\\n",
    "            'particles.d11_vap1.2Ap1Aa0.75_rdna_0.05',\\\n",
    "            'particles.d11_vap1.2Ap3.35Aa2.05rdna_0.007',\\\n",
    "            'particles.d11_vap1.5Ap1.5Aa1rdna_0.007']\n",
    "\n",
    "fldfiles = ['fields.d10_A0.5Hepp_beta0.5eps1e-4_256',\\\n",
    "            'fields.d10_A0.75Hepp_beta1_256',\\\n",
    "            'fields.d10_E11Ap3.3Aa2.0Vd0.42',\\\n",
    "            'fields.d10_E11Ap4.3Aa1.6',\\\n",
    "            'fields.d10_E11Ap4.3Aa1.6Vd0.32',\\\n",
    "            'fields.d10_E12Ap1.86Aa1.0Vd0.32_256_256x256',\\\n",
    "            'fields.d10_E12Ap1.86Aa1.0Vd0.32_512_256x256',\\\n",
    "            'fields.d10_He++A10_256_iden0eps0',\\\n",
    "            'fields.d10_He++v2_256_iden0eps1e-4t600',\\\n",
    "            'fields.d10_He++vd1.5_256_iden0eps1e-4',\\\n",
    "            'fields.d10_pv1.5_128_64_iden0eps1e-4_dx0.75_long',\\\n",
    "            'fields.d10_pv2a_128x3_iden0eps1e-4_dx0.75',\\\n",
    "            'fields.d10_pv2av2_rdna0.03375_128x3_iden0eps1e-4_dx0.75_t6000',\\\n",
    "            'fields.d10_pv2av2.3_128x3_iden0eps1e-4_dx0.75',\\\n",
    "            'fields.d10_vap1.2Ap1Aa0.75_rdna_0.05',\\\n",
    "            'fields.d10_vap1.2Ap3.35Aa2.05rdna_0.007',\\\n",
    "            'fields.d10_vap1.5Ap1.5Aa1rdna_0.007']\n",
    "\n",
    "featurevector_allmoments, labels_allmoments, timep_array = prepare_mldata_vdfmoments(simfiles[0], fldfiles[0])\n",
    "print(\"ML data for the simulation \" + simfiles[0] + \" generated\")\n",
    "print(\"Number of data points: \" + str(len(labels_allmoments)))\n",
    "featurevector_allmoments_all = np.copy(featurevector_allmoments)\n",
    "labels_allmoments_all = np.copy(labels_allmoments)\n",
    "timep_array_all = np.copy(timep_array)\n",
    "np.save('./mldata_vdfmoments/'+simfiles[0]+'.mldata_moments.npy', featurevector_allmoments)\n",
    "np.save('./mldata_vdfmoments/'+simfiles[0]+'.mldata_labels.npy', labels_allmoments)\n",
    "np.save('./mldata_vdfmoments/'+simfiles[0]+'.mldata_timep.npy', timep_array)\n",
    "\n",
    "for i in range (1, 17, 1):\n",
    "    featurevector_allmoments, labels_allmoments, timep_array = prepare_mldata_vdfmoments(simfiles[i], fldfiles[i])\n",
    "    print(\"ML data for the simulation \" + simfiles[i] + \" generated\")\n",
    "    print(\"Number of data points: \" + str(len(labels_allmoments)))\n",
    "    np.save('./mldata_vdfmoments/'+simfiles[i]+'.mldata_moments.npy', featurevector_allmoments)\n",
    "    np.save('./mldata_vdfmoments/'+simfiles[i]+'.mldata_labels.npy', labels_allmoments)\n",
    "    np.save('./mldata_vdfmoments/'+simfiles[i]+'.mldata_timep.npy', timep_array)\n",
    "    featurevector_allmoments_all = np.concatenate((featurevector_allmoments_all, featurevector_allmoments))\n",
    "    labels_allmoments_all = np.concatenate((labels_allmoments_all, labels_allmoments))\n",
    "    timep_array_all = np.concatenate((timep_array_all, timep_array))\n",
    "    \n",
    "np.save('./mldata_vdfmoments/allsimulations.mldata_moments.npy', featurevector_allmoments_all)\n",
    "np.save('./mldata_vdfmoments/allsimulations.mldata_labels.npy', labels_allmoments_all)\n",
    "np.save('./mldata_vdfmoments/allsimulations.mldata_timep.npy', timep_array_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9de793",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
